{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - Potential Talents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal(s):**\n",
    "\n",
    "Determine best matching candidates based on how fit these candidates are for a given role:\n",
    "- Predict how fit the candidate is based on their available information (variable fit).\n",
    "- Rank candidates based on a fitness score.\n",
    "- Re-rank candidates when a candidate is starred.\n",
    "\n",
    "Attributes:\n",
    "\n",
    "- id : unique identifier for candidate (numeric)\n",
    "- job_title : job title for candidate (text)\n",
    "- location : geographical location for candidate (text)\n",
    "- connections: number of connections candidate has, 500+ means over 500 (text)\n",
    "\n",
    "Output (desired target):\n",
    "\n",
    "- fit : how fit the candidate is for the role? (numeric, probability between 0-1)\n",
    "\n",
    "**Results:**\n",
    "\n",
    "- We were able to rank candidates based on a fitness score.\n",
    "- We were able to re-rank candidates when a candidate is starred.\n",
    "\n",
    "**Bonus(es):**\n",
    "\n",
    "- *We are interested in a robust algorithm, tell us how your solution works and show us how your ranking gets better with each starring action.*\n",
    "\n",
    "Once keywords are added to the initial data, these are preprocessed by eliminating punctuation, special characters, stopwords and by lemmantizing the words. For the algorithm to work, this process must be applied to the keyword chosen for the first task. Once data is preprocessed, word embeddings are obtained so that the cosine similarity function can have a correct interpretation of the data. Similar words between chosen keywords and the rest of the candidates' description will have a higher cosine similarity score. For task two candidates will be re-ranked using a different keyword which should be chosen based on a specific candidate's description. As new keywords are chosen, these become more specific to what the company is looking for which will make the algorithm get a closer match to the ideal candidate.\n",
    "\n",
    "- *How can we filter out candidates which in the first place should not be in this list?*\n",
    "\n",
    "When running the algorithm for the first time we can keep the top N results or eliminate those candidates with 0% fit result.\n",
    "\n",
    "- *Can we determine a cut-off point that would work for other roles without losing high potential candidates?*\n",
    "\n",
    "Original candidates will always be part of the original database. If filtering is applied for a specific search, this can be removed and/or modifyed for future candidate searches.\n",
    "\n",
    "- *Do you have any ideas that we should explore so that we can even automate this procedure to prevent human bias?*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *\n",
    "from state_information import USA_STATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1   2  Native English Teacher at EPIK (English Progra...   \n",
       "2   3              Aspiring Human Resources Professional   \n",
       "3   4             People Development Coordinator at Ryan   \n",
       "4   5    Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \n",
       "0                       Houston, Texas         85  NaN  \n",
       "1                               Kanada      500+   NaN  \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "3                        Denton, Texas      500+   NaN  \n",
       "4                       İzmir, Türkiye      500+   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104 entries, 0 to 103\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          104 non-null    int64  \n",
      " 1   job_title   104 non-null    object \n",
      " 2   location    104 non-null    object \n",
      " 3   connection  104 non-null    object \n",
      " 4   fit         0 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 4.2+ KB\n"
     ]
    }
   ],
   "source": [
    "file_name = 'Seeking_human_resources.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "feature_names = df.columns\n",
    "\n",
    "display(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our task is to complete de Y (fit) column, we should start by doing some data wrangling on columns job_title, location and connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values between 1-500+\n"
     ]
    }
   ],
   "source": [
    "connection_values = ['501' if x == '500+ ' else x for x in list(df['connection'].values)]\n",
    "connection_values = list(map(int, connection_values))\n",
    "print(f\"Values between {np.min(connection_values)}-500+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we will re-organize data into three categories:\n",
    "- `100-`: less than 100 connections\n",
    "- `100-500`: between 100 and 500 connections\n",
    "- `500+`: more than 500 connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_connection_feature(idd):\n",
    "    connection = df.loc[df['id'] == idd, 'connection'].values[0]\n",
    "    if connection == '500+ ': df.loc[df['id'] == idd, 'connection'] = '500+'\n",
    "    else:\n",
    "        if (int(connection) <= 500) and (int(connection) >= 100): df.loc[df['id'] == idd, 'connection'] = '100-500'\n",
    "        else: df.loc[df['id'] == idd, 'connection'] = '100-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100-       49\n",
       "500+       44\n",
       "100-500    11\n",
       "Name: connection, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'].apply(lambda x: correct_connection_feature(x))\n",
    "\n",
    "print('Value counts:')\n",
    "df['connection'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective is to add information that will be useful to detected certain paterns in text. In this case we will add the following information:\n",
    "- Add alternative spellings\n",
    "- Add english translation\n",
    "- Add US regions, divisions and state acronyms\n",
    "\n",
    "We will create a new column called `location_key_words` where all keywords will be accumulated for each `location` row. And the `location` attribute will be left with a clean version of the location for presentation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location_key_words'] = df['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_key_attribute(df, original_value, new_value, clean_value, original_att='location', key_att='location_key_words'):\n",
    "    df.loc[df[original_att] == original_value, key_att] = df.loc[df[original_att] == original_value, key_att] + ', ' + new_value\n",
    "    df.loc[df[original_att] == original_value, original_att] = clean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_key_attribute(df, original_value='Kanada', new_value='Canada', clean_value='Canada')\n",
    "add_to_key_attribute(df, original_value='İzmir, Türkiye', new_value='Izmir, Turkey', clean_value='Izmir, Turkey')\n",
    "add_to_key_attribute(df, original_value='Amerika Birleşik Devletleri', new_value='United States of America, USA, US', clean_value='USA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add state acronyms and region according to the US Census Bureau we can divide the US states into 4 Regions:\n",
    "<br><https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf>\n",
    "<br><https://www.scouting.org/resources/los/states/>\n",
    "\t \n",
    "| West | Midwest | South | Northeast |\n",
    "|-----------|---------|-------|------|\n",
    "| Arizona | Indiana | Delaware | Connecticut |\n",
    "| Colorado | Illinois | District of Columbia | Maine |\n",
    "| Idaho | Michigan | Florida | Massachusetts |\n",
    "| New Mexico | Ohio | Georgia | New Hampshire |\n",
    "| Montana | Wisconsin | Maryland | Rhode Island |\n",
    "| Utah | Iowa | North Carolina | Vermont |\n",
    "| Nevada | Kansas | South Carolina | New Jersey |\n",
    "| Wyoming | Minnesota | Virginia | New York |\n",
    "| Alaska | Missouri | West Virginia | Pennsylvania |\n",
    "| California | Nebraska | Alabama |  |\n",
    "| Hawaii | North Dakota | Kentucky |  |\n",
    "| Oregon | South Dakota | Mississippi |  |\n",
    "| Washington |  | Tennessee |  |\n",
    "|  |  | Arkansas |  |\n",
    "|  |  | Louisiana |  |\n",
    "|  |  | Oklahoma |  |\n",
    "|  |  | Texas |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>location_key_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Houston, Texas, Texas, TX, South, S, West Sout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Canada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kanada, Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area, N.C., NC,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denton, Texas, Texas, TX, South, S, West South...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>Izmir, Turkey</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>İzmir, Türkiye, Izmir, Turkey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1   2  Native English Teacher at EPIK (English Progra...   \n",
       "2   3              Aspiring Human Resources Professional   \n",
       "3   4             People Development Coordinator at Ryan   \n",
       "4   5    Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \\\n",
       "0                       Houston, Texas       100-  NaN   \n",
       "1                               Canada       500+  NaN   \n",
       "2  Raleigh-Durham, North Carolina Area       100-  NaN   \n",
       "3                        Denton, Texas       500+  NaN   \n",
       "4                        Izmir, Turkey       500+  NaN   \n",
       "\n",
       "                                  location_key_words  \n",
       "0  Houston, Texas, Texas, TX, South, S, West Sout...  \n",
       "1                                     Kanada, Canada  \n",
       "2  Raleigh-Durham, North Carolina Area, N.C., NC,...  \n",
       "3  Denton, Texas, Texas, TX, South, S, West South...  \n",
       "4                      İzmir, Türkiye, Izmir, Turkey  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for loc in df['location'].value_counts().index:\n",
    "\n",
    "    split = loc.split(' ') # split location value by ' ' to find state key words\n",
    "\n",
    "    # Special cases include states with two words or cities.\n",
    "    # In the latter case, the split value was replaced by the state name where that city belongs to\n",
    "    if 'North Carolina' in loc: split = ['North Carolina']\n",
    "    elif 'New York' in loc: split = ['New York']\n",
    "    elif ('San Francisco' in loc) and ('California' not in loc): split = ['California']\n",
    "    elif ('Philadelphia' in loc) and ('Pennsylvania' not in loc): split = ['Pennsylvania']\n",
    "    elif ('Chicago' in loc) and ('Illinois' not in loc): split = ['Illinois']\n",
    "    elif ('Los Angeles' in loc) and ('California' not in loc): split = ['California']\n",
    "    elif ('Dallas/Fort Worth' in loc) and ('Texas' not in loc): split = ['Texas']\n",
    "    elif ('Boston' in loc) and ('Massachusetts' not in loc): split = ['Massachusetts']\n",
    "    elif ('Dallas/Fort Worth' in loc) and ('Texas' not in loc): split = ['Texas']\n",
    "\n",
    "    # If it a special case, the length should be = 1 and the the split value should correspond to 1 USA_STATES key\n",
    "    if (len(split) == 1) and (split[0] in USA_STATES.keys()):\n",
    "        nv = USA_STATES[split[0]]['Standard'] + ', ' + USA_STATES[split[0]]['Postal'] + ', ' + USA_STATES[split[0]]['Region']\n",
    "        add_to_key_attribute(df, original_value=loc, new_value=nv, clean_value=loc)\n",
    "\n",
    "    # In this case split has a length of one but doesn't have value that corresponds to 1 USA_STATES key\n",
    "    elif (len(split) == 1) and (split[0] not in USA_STATES.keys()): pass\n",
    "\n",
    "    # If it isn't a special case, split's length will be > than 1. We iterate through all keywords stored in split.\n",
    "    # If the keyword corresponds to 1 USA_STATES key, add_to_key_attribute\n",
    "    else:\n",
    "        for s in split:\n",
    "            if s in USA_STATES.keys():\n",
    "                nv = USA_STATES[s]['Standard'] + ', ' + USA_STATES[s]['Postal'] + ', ' + USA_STATES[s]['Region']\n",
    "                add_to_key_attribute(df, original_value=loc, new_value=nv, clean_value=loc)\n",
    "\n",
    "df.head()  # TODO shouold I eliminate duplicates in the location_key_words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add alternative words for some cities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in df['location'].value_counts().index:\n",
    "    if 'New York City' in loc:   add_to_key_attribute(df, original_value=loc, new_value='NYC', clean_value=loc)\n",
    "    if 'Philadelphia' in loc:   add_to_key_attribute(df, original_value=loc, new_value='Philly', clean_value=loc)\n",
    "    if 'Los Angeles' in loc:   add_to_key_attribute(df, original_value=loc, new_value='LA', clean_value=loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now convert all words into lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>location_key_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 c.t. bauer college of business graduate (...</td>\n",
       "      <td>houston, texas</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>houston, texas, texas, tx, south, s, west sout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>native english teacher at epik (english progra...</td>\n",
       "      <td>canada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kanada, canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aspiring human resources professional</td>\n",
       "      <td>raleigh-durham, north carolina area</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>raleigh-durham, north carolina area, n.c., nc,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>people development coordinator at ryan</td>\n",
       "      <td>denton, texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>denton, texas, texas, tx, south, s, west south...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>advisory board member at celal bayar university</td>\n",
       "      <td>izmir, turkey</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i̇zmir, türkiye, izmir, turkey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 c.t. bauer college of business graduate (...   \n",
       "1   2  native english teacher at epik (english progra...   \n",
       "2   3              aspiring human resources professional   \n",
       "3   4             people development coordinator at ryan   \n",
       "4   5    advisory board member at celal bayar university   \n",
       "\n",
       "                              location connection  fit  \\\n",
       "0                       houston, texas       100-  NaN   \n",
       "1                               canada       500+  NaN   \n",
       "2  raleigh-durham, north carolina area       100-  NaN   \n",
       "3                        denton, texas       500+  NaN   \n",
       "4                        izmir, turkey       500+  NaN   \n",
       "\n",
       "                                  location_key_words  \n",
       "0  houston, texas, texas, tx, south, s, west sout...  \n",
       "1                                     kanada, canada  \n",
       "2  raleigh-durham, north carolina area, n.c., nc,...  \n",
       "3  denton, texas, texas, tx, south, s, west south...  \n",
       "4                     i̇zmir, türkiye, izmir, turkey  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['job_title', 'location', 'location_key_words']] = df[['job_title', 'location', 'location_key_words']].applymap(lambda x: x.lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add some abbreviations to this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_abbreviations_to_job_attribute(df, original_value, new_value):\n",
    "    df.loc[df['job_title'] == original_value, 'job_title'] = df.loc[df['job_title'] == original_value, 'job_title'] + ', ' + new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>location_key_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 c.t. bauer college of business graduate (...</td>\n",
       "      <td>houston, texas</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>houston, texas, texas, tx, south, s, west sout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>native english teacher at epik (english progra...</td>\n",
       "      <td>canada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kanada, canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aspiring human resources professional, hr, hum...</td>\n",
       "      <td>raleigh-durham, north carolina area</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>raleigh-durham, north carolina area, n.c., nc,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>people development coordinator at ryan</td>\n",
       "      <td>denton, texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>denton, texas, texas, tx, south, s, west south...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>advisory board member at celal bayar universit...</td>\n",
       "      <td>izmir, turkey</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i̇zmir, türkiye, izmir, turkey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 c.t. bauer college of business graduate (...   \n",
       "1   2  native english teacher at epik (english progra...   \n",
       "2   3  aspiring human resources professional, hr, hum...   \n",
       "3   4             people development coordinator at ryan   \n",
       "4   5  advisory board member at celal bayar universit...   \n",
       "\n",
       "                              location connection  fit  \\\n",
       "0                       houston, texas       100-  NaN   \n",
       "1                               canada       500+  NaN   \n",
       "2  raleigh-durham, north carolina area       100-  NaN   \n",
       "3                        denton, texas       500+  NaN   \n",
       "4                        izmir, turkey       500+  NaN   \n",
       "\n",
       "                                  location_key_words  \n",
       "0  houston, texas, texas, tx, south, s, west sout...  \n",
       "1                                     kanada, canada  \n",
       "2  raleigh-durham, north carolina area, n.c., nc,...  \n",
       "3  denton, texas, texas, tx, south, s, west south...  \n",
       "4                     i̇zmir, türkiye, izmir, turkey  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for job in df['job_title']:\n",
    "    if 'hr' in job: add_abbreviations_to_job_attribute(df, job, 'human resources')\n",
    "    if 'human resources' in job: add_abbreviations_to_job_attribute(df, job, 'hr')\n",
    "    if ('sr.' in job) or ('sr ' in job): add_abbreviations_to_job_attribute(df, job, 'senior')\n",
    "    if 'senior' in job: add_abbreviations_to_job_attribute(df, job, 'Sr')\n",
    "    if ('jr.' in job) or ('jr ' in job): add_abbreviations_to_job_attribute(df, job, 'junior')\n",
    "    if 'junior' in job: add_abbreviations_to_job_attribute(df, job, 'jr')\n",
    "    if 'entry-level' in job: add_abbreviations_to_job_attribute(df, job, 'entry level')\n",
    "    if 'business intelligence' in job: add_abbreviations_to_job_attribute(df, job, 'bi')\n",
    "    if 'bi' in job: add_abbreviations_to_job_attribute(df, job, 'business intelligence')\n",
    "    if 'information systems' in job: add_abbreviations_to_job_attribute(df, job, 'it')\n",
    "    if 'it' in job: add_abbreviations_to_job_attribute(df, job, 'information technology systems')\n",
    "    if 'engineer' in job: add_abbreviations_to_job_attribute(df, job, 'eng')\n",
    "    if 'bachelor of science' in job: add_abbreviations_to_job_attribute(df, job, 'bs')\n",
    "    if 'hris' in job: add_abbreviations_to_job_attribute(df, job, 'human resources information systems hr it technology')\n",
    "    if 'gis' in job: add_abbreviations_to_job_attribute(df, job, 'geographic information system it technology')\n",
    "    if 'rrp' in job: add_abbreviations_to_job_attribute(df, job, 'recommended retail price')\n",
    "    if 'mes' in job: add_abbreviations_to_job_attribute(df, job, 'manufacturing execution system')\n",
    "    if 'svp' in job: add_abbreviations_to_job_attribute(df, job, 'senior vice president sr')\n",
    "    if 'senior vice president' in job: add_abbreviations_to_job_attribute(df, job, 'svp sr')\n",
    "    if 'chief human resources officer' in job: add_abbreviations_to_job_attribute(df, job, 'chro hr')\n",
    "    if 'chro' in job: add_abbreviations_to_job_attribute(df, job, 'chief human resources officer hr')\n",
    "    if 'csr' in job: add_abbreviations_to_job_attribute(df, job, 'corporate social responsibility')\n",
    "    if 'corporate social responsibility' in job: add_abbreviations_to_job_attribute(df, job, 'csr')\n",
    "    if 'gphr' in job: add_abbreviations_to_job_attribute(df, job, 'global professional in human resources hr')\n",
    "    if 'global professional in human resources' in job: add_abbreviations_to_job_attribute(df, job, 'gphr hr')\n",
    "    if 'sphr' in job: add_abbreviations_to_job_attribute(df, job, 'senior professional in human resources hr sr')\n",
    "    if 'senior professional in human resources' in job: add_abbreviations_to_job_attribute(df, job, 'sphr hr sr')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['key_words'] = df['job_title'] + df['connection'] + df['location_key_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing and word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we finished adding keywords, we continue with the data preprocessing. We have already converted words into lower case words. We will also apply lemmatization and remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "\n",
    "    df = df.apply(lambda x: word_tokenize(x.lower()))   # tokenize: split sentence into array of words\n",
    "    df = df.apply(lambda x: list(set(word_tokenize(re.sub('[^A-Za-z*$]', ' ', str(x)))))) # remove special characters and punctuation\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df = df.apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "    df = df.apply(lambda x: ' '.join(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_encodings(corpus):\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords = stopwords.words('english')\n",
    "    tfvectoriser = TfidfVectorizer(stop_words=stopwords)\n",
    "    encoding = tfvectoriser.fit_transform(corpus)\n",
    "    encoding_df = pd.DataFrame(encoding.toarray(), columns=tfvectoriser.get_feature_names_out()) # df that contains tfidf values of each token for each row in th data\n",
    "    return encoding, encoding_df\n",
    "\n",
    "def rank_candidates(keyword, df, col):\n",
    "    corpus = df[col].tolist()\n",
    "    preprocessed_keyword = preprocess_text(pd.Series(keyword))\n",
    "    corpus.append(preprocessed_keyword.tolist()[0])\n",
    "\n",
    "    encoding, encoding_df = get_encodings(corpus)\n",
    "\n",
    "    cos_sim = cosine_similarity(encoding.toarray()[:encoding_df.shape[0]-1], encoding.toarray()[encoding_df.shape[0]-1].reshape(1, -1))\n",
    "\n",
    "    df['fit_cos_sim'] = cos_sim\n",
    "    final_df = df.sort_values('fit_cos_sim', ascending=False)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First task\n",
    "Determine best matching candidates based on how fit these candidates are for a given role based on some keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>location_key_words</th>\n",
       "      <th>key_words</th>\n",
       "      <th>fit_cos_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>canada</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kanada, canada</td>\n",
       "      <td>canada student hr generalist human humber kana...</td>\n",
       "      <td>0.343088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>canada</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kanada, canada</td>\n",
       "      <td>canada student hr generalist human humber kana...</td>\n",
       "      <td>0.343088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>canada</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kanada, canada</td>\n",
       "      <td>canada student hr generalist human humber kana...</td>\n",
       "      <td>0.343088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>canada</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kanada, canada</td>\n",
       "      <td>canada student hr generalist human humber kana...</td>\n",
       "      <td>0.343088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>student at humber college and aspiring human r...</td>\n",
       "      <td>canada</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kanada, canada</td>\n",
       "      <td>canada student hr generalist human humber kana...</td>\n",
       "      <td>0.343088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>native english teacher at epik (english progra...</td>\n",
       "      <td>canada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kanada, canada</td>\n",
       "      <td>in canada english kanada program teacher epik ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>native english teacher at epik (english progra...</td>\n",
       "      <td>canada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kanada, canada</td>\n",
       "      <td>in canada english kanada program teacher epik ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>people development coordinator at ryan</td>\n",
       "      <td>denton, texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>denton, texas, texas, tx, south, s, west south...</td>\n",
       "      <td>denton s texas ryan south central people devel...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>junior mes engineer| information systems, jr</td>\n",
       "      <td>myrtle beach, south carolina area</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>myrtle beach, south carolina area</td>\n",
       "      <td>junior south jr me system carolina area myrtle...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>104</td>\n",
       "      <td>director of administration at excellence logging</td>\n",
       "      <td>katy, texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>katy, texas, texas, tx, south, s, west south c...</td>\n",
       "      <td>tx s texas administration katy south central d...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                          job_title  \\\n",
       "49    50  student at humber college and aspiring human r...   \n",
       "38    39  student at humber college and aspiring human r...   \n",
       "24    25  student at humber college and aspiring human r...   \n",
       "51    52  student at humber college and aspiring human r...   \n",
       "6      7  student at humber college and aspiring human r...   \n",
       "..   ...                                                ...   \n",
       "19    20  native english teacher at epik (english progra...   \n",
       "1      2  native english teacher at epik (english progra...   \n",
       "17    18             people development coordinator at ryan   \n",
       "79    80       junior mes engineer| information systems, jr   \n",
       "103  104   director of administration at excellence logging   \n",
       "\n",
       "                              location connection  fit  \\\n",
       "49                              canada       100-  NaN   \n",
       "38                              canada       100-  NaN   \n",
       "24                              canada       100-  NaN   \n",
       "51                              canada       100-  NaN   \n",
       "6                               canada       100-  NaN   \n",
       "..                                 ...        ...  ...   \n",
       "19                              canada       500+  NaN   \n",
       "1                               canada       500+  NaN   \n",
       "17                       denton, texas       500+  NaN   \n",
       "79   myrtle beach, south carolina area       100-  NaN   \n",
       "103                        katy, texas       500+  NaN   \n",
       "\n",
       "                                    location_key_words  \\\n",
       "49                                      kanada, canada   \n",
       "38                                      kanada, canada   \n",
       "24                                      kanada, canada   \n",
       "51                                      kanada, canada   \n",
       "6                                       kanada, canada   \n",
       "..                                                 ...   \n",
       "19                                      kanada, canada   \n",
       "1                                       kanada, canada   \n",
       "17   denton, texas, texas, tx, south, s, west south...   \n",
       "79                   myrtle beach, south carolina area   \n",
       "103  katy, texas, texas, tx, south, s, west south c...   \n",
       "\n",
       "                                             key_words  fit_cos_sim  \n",
       "49   canada student hr generalist human humber kana...     0.343088  \n",
       "38   canada student hr generalist human humber kana...     0.343088  \n",
       "24   canada student hr generalist human humber kana...     0.343088  \n",
       "51   canada student hr generalist human humber kana...     0.343088  \n",
       "6    canada student hr generalist human humber kana...     0.343088  \n",
       "..                                                 ...          ...  \n",
       "19   in canada english kanada program teacher epik ...     0.000000  \n",
       "1    in canada english kanada program teacher epik ...     0.000000  \n",
       "17   denton s texas ryan south central people devel...     0.000000  \n",
       "79   junior south jr me system carolina area myrtle...     0.000000  \n",
       "103  tx s texas administration katy south central d...     0.000000  \n",
       "\n",
       "[104 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['key_words'] = preprocess_text(df['key_words'])\n",
    "\n",
    "keyword = 'Aspiring human resources'\n",
    "ranked_candidates = rank_candidates(keyword, df, 'key_words')\n",
    "ranked_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second task\n",
    "Once we were able to list and rank fitting candidates, the company generally employs a manual review procedure where maybe a new candidate is chosen instead of the top 1 from the previouse ranking. In this case the company needs to re-rank the previous list based on the keywords found in this new candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>location_key_words</th>\n",
       "      <th>key_words</th>\n",
       "      <th>fit_cos_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 c.t. bauer college of business graduate (...</td>\n",
       "      <td>houston, texas</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>houston, texas, texas, tx, south, s, west sout...</td>\n",
       "      <td>laude s bauer professional texas resource west...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>2019 c.t. bauer college of business graduate (...</td>\n",
       "      <td>houston, texas</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>houston, texas, texas, tx, south, s, west sout...</td>\n",
       "      <td>laude s bauer professional texas resource west...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>2019 c.t. bauer college of business graduate (...</td>\n",
       "      <td>houston, texas</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>houston, texas, texas, tx, south, s, west sout...</td>\n",
       "      <td>laude s bauer professional texas resource west...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2019 c.t. bauer college of business graduate (...</td>\n",
       "      <td>houston, texas</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>houston, texas, texas, tx, south, s, west sout...</td>\n",
       "      <td>laude s bauer professional texas resource west...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>2019 c.t. bauer college of business graduate (...</td>\n",
       "      <td>houston, texas</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>houston, texas, texas, tx, south, s, west sout...</td>\n",
       "      <td>laude s bauer professional texas resource west...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>advisory board member at celal bayar universit...</td>\n",
       "      <td>izmir, turkey</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i̇zmir, türkiye, izmir, turkey</td>\n",
       "      <td>board university i system turkey celal member ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>student at westfield state university, informa...</td>\n",
       "      <td>bridgewater, massachusetts</td>\n",
       "      <td>100-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bridgewater, massachusetts, mass., ma, northea...</td>\n",
       "      <td>student ma massachusetts university ne westfie...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>rrp brand portfolio executive at jti (japan to...</td>\n",
       "      <td>greater philadelphia area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>greater philadelphia area, p.a, pa, northeast,...</td>\n",
       "      <td>recommended retail price p northeast area at j...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>undergraduate research assistant at styczynski...</td>\n",
       "      <td>greater atlanta area</td>\n",
       "      <td>100-500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>greater atlanta area</td>\n",
       "      <td>lab styczynski area assistant atlanta greater ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>native english teacher at epik (english progra...</td>\n",
       "      <td>canada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kanada, canada</td>\n",
       "      <td>in canada english kanada program teacher epik ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "0    1  2019 c.t. bauer college of business graduate (...   \n",
       "43  44  2019 c.t. bauer college of business graduate (...   \n",
       "56  57  2019 c.t. bauer college of business graduate (...   \n",
       "14  15  2019 c.t. bauer college of business graduate (...   \n",
       "30  31  2019 c.t. bauer college of business graduate (...   \n",
       "..  ..                                                ...   \n",
       "22  23  advisory board member at celal bayar universit...   \n",
       "94  95  student at westfield state university, informa...   \n",
       "84  85  rrp brand portfolio executive at jti (japan to...   \n",
       "89  90  undergraduate research assistant at styczynski...   \n",
       "15  16  native english teacher at epik (english progra...   \n",
       "\n",
       "                      location connection  fit  \\\n",
       "0               houston, texas       100-  NaN   \n",
       "43              houston, texas       100-  NaN   \n",
       "56              houston, texas       100-  NaN   \n",
       "14              houston, texas       100-  NaN   \n",
       "30              houston, texas       100-  NaN   \n",
       "..                         ...        ...  ...   \n",
       "22               izmir, turkey       500+  NaN   \n",
       "94  bridgewater, massachusetts       100-  NaN   \n",
       "84   greater philadelphia area       500+  NaN   \n",
       "89        greater atlanta area    100-500  NaN   \n",
       "15                      canada       500+  NaN   \n",
       "\n",
       "                                   location_key_words  \\\n",
       "0   houston, texas, texas, tx, south, s, west sout...   \n",
       "43  houston, texas, texas, tx, south, s, west sout...   \n",
       "56  houston, texas, texas, tx, south, s, west sout...   \n",
       "14  houston, texas, texas, tx, south, s, west sout...   \n",
       "30  houston, texas, texas, tx, south, s, west sout...   \n",
       "..                                                ...   \n",
       "22                     i̇zmir, türkiye, izmir, turkey   \n",
       "94  bridgewater, massachusetts, mass., ma, northea...   \n",
       "84  greater philadelphia area, p.a, pa, northeast,...   \n",
       "89                               greater atlanta area   \n",
       "15                                     kanada, canada   \n",
       "\n",
       "                                            key_words  fit_cos_sim  \n",
       "0   laude s bauer professional texas resource west...          1.0  \n",
       "43  laude s bauer professional texas resource west...          1.0  \n",
       "56  laude s bauer professional texas resource west...          1.0  \n",
       "14  laude s bauer professional texas resource west...          1.0  \n",
       "30  laude s bauer professional texas resource west...          1.0  \n",
       "..                                                ...          ...  \n",
       "22  board university i system turkey celal member ...          0.0  \n",
       "94  student ma massachusetts university ne westfie...          0.0  \n",
       "84  recommended retail price p northeast area at j...          0.0  \n",
       "89  lab styczynski area assistant atlanta greater ...          0.0  \n",
       "15  in canada english kanada program teacher epik ...          0.0  \n",
       "\n",
       "[104 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_id = 0\n",
    "new_ranked_candidates = rank_candidates(ranked_candidates.loc[candidate_id, 'key_words'], df, 'key_words')\n",
    "new_ranked_candidates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('apziva-p1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d58a6346ebf7422e603e868fb3854851aa5811b3024e6952b5df4a7c1ed6fa8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
